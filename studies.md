# Potential studies:

## Causal Role of Attention Heads

- [x] Which attention heads are critical for predicting the next token?
- [x] Can we identify redundant heads?

## Compositional Structure in Attention

- [ ] Do certain heads focus on specific linguistic features (e.g., subject- [ ]verb agreement)?
- [ ] Can permuting attention outputs break coherence?

## Sparse Representations in Transformer Attention

- [ ]Does structured sparsification reveal essential vs. inessential heads?
- [ ] Are there clusters of heads that work together?

## Progression Across Layers

- [ ] Do early layers focus on local dependencies while later layers capture abstract meaning?
- [ ] How do attention patterns change from input tokens to final predictions?